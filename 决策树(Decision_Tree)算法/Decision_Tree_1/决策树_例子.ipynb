{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：计算香农熵\n",
    "参数说明：\n",
    "    dataSet ：原始数据集\n",
    "返回：\n",
    "    end：香农熵的值\n",
    "'''\n",
    "def calEnt(dataSet):\n",
    "    n = dataSet.shape[0] #数据总行数\n",
    "    #print(dataSet)\n",
    "    iset = dataSet.iloc[:,-1].value_counts() #标签的所有类别\n",
    "    #print(list(iset))\n",
    "    p = iset / n  # 每一类标签所占比\n",
    "    #print(list(p))\n",
    "    ent = (-p * np.log2(p)).sum() # 计算信息熵\n",
    "    return ent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def createDataSet():\n",
    "    row_data = {'no surfacing':[1,1,1,0,0],\n",
    "                'flippers':[1,1,0,1,1],\n",
    "                'fish':['yes','yes','no','no','no']}\n",
    "    dataSet = pd.DataFrame(row_data)\n",
    "    return dataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish\n",
       "0             1         1  yes\n",
       "1             1         1  yes\n",
       "2             1         0   no\n",
       "3             0         1   no\n",
       "4             0         1   no"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = createDataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：根据信息增益选择出最佳数据集切分的列\n",
    "参数说明：\n",
    "    dataSet：原始数据集\n",
    "返回：\n",
    "    axis：数据集最佳切分列的索引\n",
    "'''\n",
    "# 选择最优的列进行切分\n",
    "def bestSplit(dataSet):\n",
    "    baseEnt = calEnt(dataSet) # 计算原始熵\n",
    "    bestGain = 0 # 初始化信息增益\n",
    "    axis = -1 # 初始化最佳分列，标签列\n",
    "    for i in range( dataSet.shape[1] - 1): # 对特征的每一列进行循环\n",
    "        levels = dataSet.iloc[:,i].value_counts().index # 提取出当前列的所有值\n",
    "        #print(levels)\n",
    "        ents = 0 #初始化子节点的信息熵\n",
    "        for j in levels:  # 对当前列的每一个取值进行循环\n",
    "            childSet = dataSet[dataSet.iloc[:,i]==j] # 某一个子节点的dataFrame\n",
    "            #print(childSet)\n",
    "            ent = calEnt(childSet) # 计算子节点的信息熵\n",
    "            ents += (childSet.shape[0]/dataSet.shape[0])*ent # 计算当前列的信息熵\n",
    "        infoGain = baseEnt - ents  #　计算当前列的信息增益\n",
    "        if(infoGain > bestGain):\n",
    "            bestGain = infoGain# 选取最大的信息增益\n",
    "            axis = i # 最大信息增益列所在的索引\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestSplit(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：按照给定的列划分数据集\n",
    "参数说明：\n",
    "    dataSet: 原始数据集\n",
    "    axis: 指定的列索引\n",
    "    value：指定的属性值\n",
    "返回：\n",
    "    redataSet：按照指定列数索引和属性值切分后的数据集\n",
    "'''\n",
    "def mySplit(dataSet,axis,value):\n",
    "    col = dataSet.columns[axis] # col = no surfacing\n",
    "    #print(col)\n",
    "    redataSet = dataSet.loc[dataSet[col] == value,:].drop(col,axis=1)\n",
    "    return redataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surfacing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flippers fish\n",
       "0         1  yes\n",
       "1         1  yes\n",
       "2         0   no"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySplit(dataSet,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：基于最大信息增益切分数据集，递归构建决策树\n",
    "参数说明：\n",
    "    dataSet: 原始数据集（最后一列是标签）\n",
    "返回：\n",
    "    myTree：字典形式的树\n",
    "'''\n",
    "def createTree(dataSet):\n",
    "    featlist = list(dataSet.columns) # 提取出数据集所有的列\n",
    "    # print(featlist)--->['no surfacing', 'flippers', 'fish']\n",
    "    classlist = dataSet.iloc[:,-1].value_counts() # 获取最后一列类标签\n",
    "    # print(list(classlist))-->[3, 2]\n",
    "    # 判断最多标签数目是否等于数据集行数，或者数据集是否只有一列\n",
    "    if classlist[0] == dataSet.shape[0] or dataSet.shape[1] == 1:\n",
    "        return classlist.index[0] # 如果是，返回类标签\n",
    "    axis = bestSplit(dataSet) # 确定出当前最佳分裂的索引\n",
    "    bestfeat = featlist[axis] # 获取该索引列对应的特征\n",
    "    myTree = {bestfeat:{}} # 采用字典嵌套的方式存储树信息\n",
    "    del featlist[axis] # 删除当前特征\n",
    "    valuelist = set(dataSet.iloc[:,axis]) # 提取最佳分列所有属性值\n",
    "    for value in valuelist: # 对每一个属性值递归建树\n",
    "        myTree[bestfeat][value] = createTree(mySplit(dataSet,axis,value))\n",
    "        #print(myTree)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree = createTree(dataSet)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树的存储\n",
    "np.save('myTree.npy',myTree)\n",
    "\n",
    "# 树的读取\n",
    "read_myTree = np.load('myTree.npy').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：对一个测试实例进行分类\n",
    "参数说明：\n",
    "    inputTree：已经生成的决策树\n",
    "    labels：存储选择的最优特征标签\n",
    "    testVec：测试数据列表，顺序对应原数据\n",
    "返回：\n",
    "    classlabel：分类结果\n",
    "'''\n",
    "def classify(inputTree,labels,testVec):\n",
    "    firstStr = next(iter(inputTree)) # 获取决策树的第一个节点\n",
    "    secondDict = inputTree[firstStr] # 下一个字典\n",
    "    #print(secondDict)\n",
    "    featIndex = labels.index(firstStr) # 第一个节点所在列的索引\n",
    "    #print(featIndex)\n",
    "    for key in secondDict.keys():\n",
    "        #print(key)\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]) == dict:\n",
    "                classLabel = classify(secondDict[key],labels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：对测试集进行预测，并返回预测后的结果\n",
    "函数说明：\n",
    "    train: 训练集\n",
    "    test：测试集\n",
    "返回：\n",
    "    test：预测好分类的测试集\n",
    "'''\n",
    "def acc_classify(train,test):\n",
    "    inputTree = createTree(train) # 根据训练集生成一棵树\n",
    "    # print(inputTree)-->{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
    "    labels = list(train.columns)  # 数据集所有的列名称\n",
    "    result = [] \n",
    "    for i in range(test.shape[0]): # 对测试集中每一天数据进行循环\n",
    "        testVec = test.iloc[i,: -1] # 测试集中的一个实例\n",
    "        classLabel = classify(inputTree,labels,testVec) # 预测该实例的分类\n",
    "        result.append(classLabel) # 将预测结果追加到result列表中\n",
    "    test['predict'] = result # 将预测结果追加到测试集的最后一列\n",
    "    acc = (test.iloc[:,-1] == test.iloc[:,-2]).mean() # 计算准确率\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish predict\n",
       "0             1         1  yes     yes\n",
       "1             1         1  yes     yes\n",
       "2             1         0   no      no"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = createDataSet()\n",
    "test = dataSet.iloc[:3,:]\n",
    "\n",
    "acc_classify(train , test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
